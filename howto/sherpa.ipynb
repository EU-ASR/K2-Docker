{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sherpa Docker info \n",
    "\n",
    "For Jupyter:\n",
    "* Needs `bash` kernel not Python\n",
    "* To allow scrollable output for Jupyter outputs \n",
    "* Interactive (waiting for user input) shell commands does not work in notebook because they block and wait for the user input..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# Convert this notebook to markdown format file sherpa.md\n",
    "jupyter nbconvert --to markdown sherpa.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Install Docker\n",
    "\n",
    "To install docker engine you can follow the original guide for your os\n",
    "[Install Docker Engine](https://docs.docker.com/engine/install/)\n",
    "\n",
    "or use the following version for ubuntu\n",
    "\n",
    "### Install\n",
    "\n",
    "Official Guide: [Install on Ubuntu](https://docs.docker.com/engine/install/ubuntu/)\n",
    "\n",
    "If on Ubuntu then you can install Docker with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo apt-get update\n",
    "sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "And test if it's installed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo docker run hello-world"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linux post-install\n",
    "\n",
    "Note that the command after install was run with sudo, to manage docker as non-root user complete \n",
    "[linux post-install](https://docs.docker.com/engine/install/linux-postinstall/)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo groupadd docker\n",
    "sudo usermod -aG docker $USER"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "than logout and login to activate changes to groups and run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "newgrp docker\n",
    "docker run hello-world"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To configure Docker to start on boot with systemd you need to run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo systemctl enable docker.service\n",
    "sudo systemctl enable containerd.service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building image\n",
    "\n",
    "The images are built in CI/CD pipelines, however we can build them locally.\n",
    "\n",
    "Building image with specified Dockerfile `linux-64-cpu-python.Dockerfile` from root project directory:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker build -f linux-64-cpu-python.Dockerfile --tag sherpa-python:linux-64-cpu ."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "you can view the image with \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker image ls"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "or remove it with\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker image rm $IMAGE_ID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `IMAGE_ID` is short unique image hash such as `b273004037cc`. There is also command `docker prune` or `docker image prune` which can be quite usefull for clean-up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pulling image\n",
    "\n",
    "To pull already build image from remote Docker container registry https://github.com/Andyy42/sherpa/pkgs/container/sherpa (this one is GitHub Container Registry - **ghcr**).  you can run\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker pull ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker lifecycle\n",
    "\n",
    "Simplified version of Docker lifecycle\n",
    "\n",
    "![Docker lifecycle](https://k21academy.com/wp-content/uploads/2020/10/Capture-5.png)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Running containers \n",
    "\n",
    "Image which is currently used is called conatiner. To run container interactively do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run --rm -ti ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run --rm -ti --entrypoint bash ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "where `--rm` automatically removes container when in exists, `-t` allocates pseudo-TTY and `-i` will\n",
    "enter interactive mode (keep STDIN open even if not attached).\n",
    "\n",
    "The running Docker container will start `bash` shell from which you can use it.\n",
    "Note that containers have usually specified `ENTRYPOINT`\n",
    "which can be a start-up script for webserver or any other script. To override it\n",
    "we run `--entrypoint bash`. \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now we are in `bash`, try to play with it. To detach from such container we can do `CTRL+P`, `CTRL+Q`\n",
    "but the container is till running in the background and we can return to it but first we need the container id!\n",
    "To list **running** only containers do: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker ps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can either use `CONTAINER_ID` or `NAME`, we'll go with `CONTAINER_ID` for now and attach to the container:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "CONTAINER_ID=PUT_ID_HERE\n",
    "docker attach $CONTAINER_ID"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also execute something inside the Docker container (this will run separately from currently running process inside the container)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker exec -ti $CONTAINER_ID bash"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get image ID use `docker container ls` to list running containers. To remove this container\n",
    "we can either use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker container stop $CONTAINER_ID \n",
    "docker container rm $CONTAINER_ID "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "or simply exit from the atteched container (becuase we used the `--rm` flag)\n",
    "\n",
    "We can also use this command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run --rm -ti ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu sherpa-version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "where the entrypoint is used the defualt (bash in this case) and runs commands passed to it\n",
    "which are after image tag `ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu`, which is `sherpa-version`\n",
    "in this case.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Docker and volumes \n",
    "\n",
    "* Volumes https://docs.docker.com/storageo/volumes/\n",
    "* Bind mounts https://docs.docker.com/storage/bind-mounts/\n",
    "* `tmpfs` mounts (not important for us and not used very often)\n",
    "\n",
    "![Volumes with docker](https://docs.docker.com/storage/images/types-of-mounts-volume.png)\n",
    "\n",
    "**NOTE:** Both volumes and bind mounts are created with `-v`, `--volume` or `--mount` (mount is more verbose)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Note about users, groups and file permissions\n",
    "\n",
    "* To simplify, Docker can be viewed as a combination of `cgroups` and `namespaces`.\n",
    "* `namespaces` are used to isoloate **host user:group** space from the container's **user:group space**.\n",
    "\n",
    "If running docker root-less you do it by defining mapping for the user which currently runs the docker. Container's UID and GID starts from that number. The mapping is specified in:\n",
    "```bash\n",
    "/etc/subuid # For UID\n",
    "/etc/subgid # For GID\n",
    "```\n",
    "So user with UID 0 is mapped to a starting number (100000 for example) in `\\etc\\subuid`. This might cause issues with permissions!\n",
    "\n",
    "Easy workaround is to set correct permissions for the folder we want to use as a volume. Or if we do not care about permissions in our current sitation just use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "sudo chmod -R 0777 <path_to_dir> "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*NOTE: chmod 0777 is workaround, there is better option to manage permissions!*\n",
    "\n",
    "Or you can create some technical user like `docker-root` which maps to `root` user in running container (they have same ID in host OS)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained models demo\n",
    "\n",
    "To try pretrained models you can use **sherpa** documentation: [Pre-trained models for C++ users](https://k2-fsa.github.io/sherpa/cpp/pretrained_models/offline_ctc/icefall.html)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### [Offline transducer models](https://k2-fsa.github.io/sherpa/cpp/pretrained_models/offline_transducer.html)\n",
    "#### icefall-asr-gigaspeech-conformer-ctc (English)\n",
    "\n",
    "This section is copied from the documentation. Firstly download the model with `git lfs pull`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# This model is trained using GigaSpeech + LibriSpeech with zipformer\n",
    "#\n",
    "# See https://github.com/k2-fsa/icefall/pull/728\n",
    "#\n",
    "GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/WeijiZhuang/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02\n",
    "cd icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02\n",
    "git lfs pull --include \"exp/cpu_jit-torch-1.10.pt\"\n",
    "git lfs pull --include \"data/lang_bpe_500/LG.pt\"\n",
    "\n",
    "cd exp\n",
    "rm cpu_jit.pt\n",
    "ln -sv cpu_jit-torch-1.10.pt cpu_jit.pt\n",
    "cd .."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now run the container with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run --rm -ti -v $(pwd)/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02/:/opt/models/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02 \\\n",
    "  -p 6006:6006--entrypoint bash --name sherpa ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "MODEL=/opt/models/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02\n",
    "# Decode with H\n",
    "sherpa-offline \\\n",
    "  --nn-model=$MODEL/exp/cpu_jit.pt \\\n",
    "  --hlg=$MODEL/data/lang_bpe_500/HLG.pt \\\n",
    "  --tokens=$MODEL/data/lang_bpe_500/tokens.txt \\\n",
    "  $MODEL/test_wavs/1089-134686-0001.wav \\\n",
    "  $MODEL/test_wavs/1221-135766-0001.wav \\\n",
    "  $MODEL/test_wavs/1221-135766-0002.wav\n",
    "\n",
    "# Decode with HLG\n",
    "sherpa-offline \\\n",
    "  --nn-model=$MODEL/exp/cpu_jit.pt \\\n",
    "  --hlg=$MODEL/data/lang_bpe_500/HLG.pt \\\n",
    "  --tokens=$MODEL/data/lang_bpe_500/tokens.txt \\\n",
    "  $MODEL/test_wavs/1089-134686-0001.wav \\\n",
    "  $MODEL/test_wavs/1221-135766-0001.wav \\\n",
    "  $MODEL/test_wavs/1221-135766-0002.wav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can mount `models/` dir from our local filesystem to `/opt/models` in docker container filesystem with `-v /path/to/models:/opt/models`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Online transducer models](https://k2-fsa.github.io/sherpa/cpp/pretrained_models/online_transducer.html)\n",
    "(did not work: `icefall-asr-librispeech-pruned-transducer-stateless7-streaming-2022-12-29`)\n",
    "\n",
    "#### icefall-asr-librispeech-conv-emformer-transducer-stateless2-2022-07-05\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "# This model is trained using LibriSpeech with ConvEmformer transducer\n",
    "#\n",
    "# See https://github.com/k2-fsa/icefall/pull/440\n",
    "#\n",
    "GIT_LFS_SKIP_SMUDGE=1 git clone https://huggingface.co/Zengwei/icefall-asr-librispeech-conv-emformer-transducer-stateless2-2022-07-05\n",
    "cd icefall-asr-librispeech-conv-emformer-transducer-stateless2-2022-07-05\n",
    "\n",
    "git lfs pull --include \"exp/cpu-jit-epoch-30-avg-10-torch-1.10.0.pt\"\n",
    "git lfs pull --include \"data/lang_bpe_500/LG.pt\"\n",
    "cd exp\n",
    "ln -sv cpu-jit-epoch-30-avg-10-torch-1.10.0.pt cpu_jit.pt\n",
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker run --rm -ti -v $(pwd)/icefall-asr-librispeech-conv-emformer-transducer-stateless2-2022-07-05/:/opt/models/icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02 \\\n",
    "  -p 6006:6006--entrypoint bash --name sherpa ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "MODEL=/opt/models/icefall-asr-librispeech-conv-emformer-transducer-stateless2-2022-07-05\n",
    "for m in greedy_search modified_beam_search fast_beam_search; do\n",
    "  sherpa-online \\\n",
    "    --decoding-method=$m \\\n",
    "    --nn-model=$MODEL/exp/cpu_jit.pt \\\n",
    "    --tokens=$MODEL/data/lang_bpe_500/tokens.txt \\\n",
    "    $MODEL/test_wavs/1089-134686-0001.wav \\\n",
    "    $MODEL/test_wavs/1221-135766-0001.wav \\\n",
    "    $MODEL/test_wavs/1221-135766-0002.wav\n",
    "done\n",
    "\n",
    "# For fast_beam_search with LG\n",
    "sherpa-online \\\n",
    "  --decoding-method=fast_beam_search \\\n",
    "  --nn-model=$MODEL/exp/cpu_jit.pt \\\n",
    "  --lg=./data/lang_bpe_500/LG.pt \\\n",
    "  --tokens=$MODEL/data/lang_bpe_500/tokens.txt \\\n",
    "  $MODEL/test_wavs/1089-134686-0001.wav \\\n",
    "  $MODEL/test_wavs/1221-135766-0001.wav \\\n",
    "  $MODEL/test_wavs/1221-135766-0002.wav"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can mount `models/` dir from our local filesystem to `/opt/models` in docker container filesystem with `-v /path/to/models:/opt/models`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker-compose\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running containers with `docker run` is nice but imagine you have to spin up three containers, create networking for them, add volumes etc...\n",
    "\n",
    "Fortunately, `docker-compose` comes to rescue and we can define how will the docker containers run with code.\n",
    "\n",
    "The shell command: \n",
    "```bash\n",
    "docker run --rm -ti -v /path/to/models/:/opt/models/ \\\n",
    "  -p 6006:6006--entrypoint bash --name sherpa ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu \\\n",
    "```\n",
    "\n",
    "Can be roughly re-written to `docker-compose.yml`:\n",
    "```yaml\n",
    "services:\n",
    "    sherpa:\n",
    "        image: ghcr.io/andyy42/sherpa:dockerfile-linux-64-cpu\n",
    "        ports: 6006:6006\n",
    "        volumes:\n",
    "            -  /path/to/models/:/opt/models/\n",
    "        entrypoint:\n",
    "            - bash\n",
    "```\n",
    "\n",
    "It introduces new commands:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose up           # Starts all services (containers)\n",
    "docker-compose down         # Stops and remove containers, networks, ...\n",
    "docker-compose run $SERVICE # Runs one-off command on a service (can also start single service such as `sherpa`)\n",
    "docker-compose stop         # Stops running containers\n",
    "docker-compose start        # Start stopped containers\n",
    "docker-compose build        # Build/rebuild services if `build` defined\n",
    "..."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IIS proj example\n",
    "\n",
    "This is just and *illustrative example* how to use `docker-compose` in context of web app to show it's potential.\n",
    "\n",
    "Web app with:\n",
    "* Django (Python) **backend** - `backend` service\n",
    "* React (JS) **frontend** - static frontend served by `nginx` service\n",
    "* Postgres **database** - `db` service\n",
    "* nginx **reverse proxy** which also serves static frontend - `nginx` service"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "---\n",
    "version: '3'\n",
    "\n",
    "services:\n",
    "    db:\n",
    "        env_file:\n",
    "            - .env.local\n",
    "        image: postgres:14-alpine\n",
    "        volumes:\n",
    "            - ./data/db:/var/lib/postgresql/data\n",
    "    backend:\n",
    "        build:\n",
    "            context: .\n",
    "            dockerfile: ./docker/backend/Dockerfile\n",
    "        entrypoint: /app/docker/backend/wsgi-entrypoint.sh\n",
    "        expose:\n",
    "            - 8000\n",
    "        environment:\n",
    "            - DOCKER_COMPOSE=1\n",
    "        restart: unless-stopped\n",
    "        volumes:\n",
    "            - static_volume:/app/backend/django_static\n",
    "        depends_on:\n",
    "            - db\n",
    "    nginx:\n",
    "        build:\n",
    "            context: .\n",
    "            dockerfile: ./docker/nginx/Dockerfile\n",
    "        depends_on:\n",
    "            - backend\n",
    "        ports:\n",
    "            - '80:80'\n",
    "        restart: unless-stopped\n",
    "        volumes:\n",
    "            - static_volume:/app/backend/django_static\n",
    "            - ./docker/nginx/development:/etc/nginx/conf.d\n",
    "\n",
    "volumes:\n",
    "    static_volume: {}\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Docker-compose in sherpa\n",
    "\n",
    "More complex example how to use `docker-compose` with sherpa to automate `docker` commands\n",
    "\n",
    "`.env` file with pre-populated variables:\n",
    "```bash\n",
    "SHERPA_TAG=dockerfile-linux-64-cpu\n",
    "SHERPA_COMMAND=sherpa-offline-websocket-server\n",
    "SHERPA_COMMAND_EXTRA_ARGS=\"--max-utterance-length=300\"\n",
    "SHERPA_TOKENS_PATH=data/lang_bpe_500/tokens.txt\n",
    "SHERPA_NN_MODEL_PATH=exp/cpu_jit.pt\n",
    "SHERPA_PORT=6006\n",
    "SHERPA_MODEL_NAME=icefall-asr-librispeech-pruned-transducer-stateless8-2022-12-02\n",
    "SHERPA_MODEL_PATH=\"../../models\"\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "`docker-compose.yml` with definitions how to compose docker:\n",
    "```yaml\n",
    "version: \"3.8\"\n",
    "services:\n",
    "  sherpa:\n",
    "    image: \"ghcr.io/andyy42/sherpa:${SHERPA_TAG}\"\n",
    "    entrypoint:\n",
    "      - ${SHERPA_COMMAND}\n",
    "      - --port=6006\n",
    "      - --use-gpu=false\n",
    "      - --num-io-threads=3\n",
    "      - --num-work-threads=5\n",
    "      - --max-batch-size=5\n",
    "      - --nn-model=/opt/models/${SHERPA_MODEL_NAME}/${SHERPA_NN_MODEL_PATH}\n",
    "      - --tokens=/opt/models/${SHERPA_MODEL_NAME}/${SHERPA_TOKENS_PATH}\n",
    "      - --decoding-method=greedy_search\n",
    "      - --log-file=/var/log/sherpa.log\n",
    "      - --doc-root=/app/sherpa/web/\n",
    "      - ${SHERPA_COMMAND_EXTRA_ARGS:---}}\n",
    "    working_dir: /app/sherpa\n",
    "    ports:\n",
    "      - ${SHERPA_PORT}:6006\n",
    "    volumes:\n",
    "      - ${SHERPA_MODEL_PATH}:/opt/models/\n",
    "```\n",
    "\n",
    "With `docker-compose` you can specify different `.env` files with `--env-file`\n",
    "or `docker-compose.yml` with `--file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose --file docker-compose.yml --env-file online.env up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "docker-compose --file docker-compose.yml --env-file offline.env up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demo with [Ngrok](https://ngrok.com/docs/)\n",
    "\n",
    "`ngrok` is the fastest way to host and secure your applications and services on the internet.\n",
    "It is good for quick testing. Creates tunnel with specified port and opens it to the internet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ngrok http 6006 --region eu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Websocket` endpoints work through ngrok's `http` tunnels without any changes. Or you can open `tcp` port directly as"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "ngrok tcp 6006 --region eu"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** ngrok defualt region is not `eu` (Frankfurt) but `usa`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "NOTE: I found it quite usefull to use ChatGPT4 for Docker commands or even better\n",
    "with [shell GPT](https://github.com/TheR1D/shell_gpt) command `sgpt`.\n",
    "\n",
    "TODO: Networking between several docker containers was not fully covered\n",
    "\n",
    "TODO: Docker volumes for models (there are more options..)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
